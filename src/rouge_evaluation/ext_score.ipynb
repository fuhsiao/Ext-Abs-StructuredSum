{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c60c7c-5681-4f0d-80e5-dd646dd46d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from eval_utils import read_pmcids, sent_json, load_ExtModel, TrigramBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b2d9ad-f830-449f-9700-15a1c52eb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_PATH = '../../dataset/pmcids/test.txt'\n",
    "JSON_DIR = '../../dataset/sentence_json/'\n",
    "PARQUET_DIR = '../../dataset/sentence_features/'\n",
    "MODEL = load_ExtModel('../extractive_summarizer/model/LGB_model_F10_S.pkl')\n",
    "BLOCK = ['F8','F9','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31213835-c106-4283-94b6-7ecb265f2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence_df(sentJson, pred, true_proba):\n",
    "    \n",
    "    # 摘要、正文 轉換為 DataFrame\n",
    "    abstract = pd.DataFrame([(section, sent['text'].strip()) for section in 'IMRD' for sent in sentJson['abstract'][section]],\n",
    "                       columns=['section', 'text']).astype({'section': 'category', 'text': 'string'})\n",
    "    \n",
    "    body = pd.DataFrame([(section, sent['text'].strip(), sent['label']) for section in 'IMRD' for sent in sentJson['body'][section]],\n",
    "                       columns=['section', 'text', 'label']).astype({'section': 'category', 'text': 'string', 'label': 'bool'})\n",
    "\n",
    "    # 加上預測結果和機率\n",
    "    body['predict'] = pred.astype('bool')\n",
    "    body['proba'] = true_proba.astype('float16')\n",
    "\n",
    "    \n",
    "    # 對每章節的提取句子進行 trigram blocking\n",
    "    if set_trigram_blocking:\n",
    "        for section in 'IMRD':\n",
    "            block = TrigramBlock()\n",
    "            temp = body.loc[(body['section'] == section) & (body['predict'] == True)].sort_values(by='proba', ascending=False)\n",
    "            for i, row in temp.iterrows():\n",
    "                if block.check_overlap(row['text']):\n",
    "                    body.at[i, 'predict'] = False \n",
    "                    \n",
    "    return body, abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83223f1-528e-4b17-be07-d7442c00d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(pmcid, threshold,\n",
    "                    model=MODEL, block_cols=BLOCK, json_dir=JSON_DIR, parquet_dir=PARQUET_DIR):\n",
    "    \n",
    "    # 預測\n",
    "    def predict(x):\n",
    "        true_proba = model.predict_proba(x)[:, 1]\n",
    "        # 如果沒有任何句子的預測機率大於閾值，則選取最大機率的句子為摘要句\n",
    "        if not np.any(true_proba > threshold):\n",
    "            true_proba[true_proba == np.max(true_proba)] = 1\n",
    "        pred = (true_proba > threshold).astype('int')\n",
    "        return pred, true_proba\n",
    "    \n",
    "    # 讀取句子特徵，進行預測\n",
    "    df = pd.read_parquet(f'{parquet_dir}/{pmcid}.parquet')\n",
    "    sentFeat  = df.drop(columns=block_cols)\n",
    "    pred, true_proba = predict(sentFeat)\n",
    "    \n",
    "    # 讀取句子資料，組合對應文本\n",
    "    sentJson = sent_json(f'{json_dir}/{pmcid}.json')\n",
    "    body, abstract = convert_sentence_df(sentJson, pred, true_proba)\n",
    "    ext = body[body['predict'] == True]\n",
    "    \n",
    "    return ext, abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485741f1-4a41-4411-9901-337b67a2f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均 ROUGE 分數\n",
    "def main(pmcid_file=IDS_PATH, threshold=0.5):    \n",
    "    \n",
    "    rouge = evaluate.load('rouge')\n",
    "    pmcids = read_pmcids(pmcid_file)\n",
    "    lst = ['ALL', 'I', 'M', 'R', 'D']\n",
    "    hyp = {key: [] for key in lst}\n",
    "    ref = {key: [] for key in lst}\n",
    "    \n",
    "    for pmcid in pmcids:\n",
    "        ext, abstract = process_article(pmcid, threshold)\n",
    "        for section in lst:\n",
    "            hyp_txt = '\\n'.join(list(ext['text'])) if section == 'ALL' else '\\n'.join(list(ext[ext['section']==section]['text']))\n",
    "            ref_txt = '\\n'.join(list(abstract['text'])) if section == 'ALL' else '\\n'.join(list(abstract[abstract['section']==section]['text']))\n",
    "            hyp[section].append(hyp_txt)\n",
    "            ref[section].append(ref_txt)\n",
    "    \n",
    "    res = {key: rouge.compute(predictions=hyp[key], references=ref[key], use_stemmer=True, use_aggregator=True) for key in lst}\n",
    "    return pd.DataFrame(res).round(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf57d6-e5d6-4f1b-8104-41553a33eeb3",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661833ae-67a1-4a58-9f39-067f8c5f6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 39s, sys: 2.48 s, total: 36min 42s\n",
      "Wall time: 24min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "      <th>R</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.2065</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.3310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ALL       I       M       R       D\n",
       "rouge1     0.3246  0.3039  0.2683  0.2809  0.3642\n",
       "rouge2     0.1893  0.1607  0.1210  0.1640  0.2111\n",
       "rougeL     0.2065  0.2136  0.1759  0.1994  0.2778\n",
       "rougeLsum  0.3110  0.2788  0.2439  0.2626  0.3310"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "set_trigram_blocking=False\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c09a85b-c23f-4521-9662-e57eeaf14192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 12s, sys: 3.93 s, total: 31min 16s\n",
      "Wall time: 15min 36s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "      <th>R</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.4251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.2325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>0.3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>0.4354</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>0.3788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ALL       I       M       R       D\n",
       "rouge1     0.4608  0.3781  0.3297  0.3858  0.4251\n",
       "rouge2     0.2194  0.1802  0.1324  0.1677  0.2325\n",
       "rougeL     0.2511  0.2555  0.2055  0.2359  0.3167\n",
       "rougeLsum  0.4354  0.3394  0.2939  0.3461  0.3788"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "set_trigram_blocking=True\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69612a-5493-4aaf-83da-2fd454f1f5bd",
   "metadata": {},
   "source": [
    "### Output sentence pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90198c9-b8fd-4b49-a6a7-2ce91395f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出預測摘要/參考摘要句子對 (作為生成式模型訓練資料)\n",
    "def generate_ext_abstract_pairs(pmcid_file, output_file, threshold, batch_size=5000):\n",
    "    pmcids = read_pmcids(pmcid_file)\n",
    "    num = 0\n",
    "    pairs = []\n",
    "    append_mode = False\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        append_mode = True\n",
    "    \n",
    "    # 批量輸出\n",
    "    def output_batch(pairs, output_file, append_mode):\n",
    "        pairs_arr = np.array(pairs)\n",
    "        df = pd.DataFrame({'extract': pairs_arr[:, 0], 'abstract': pairs_arr[:, 1]}) \n",
    "        if append_mode:\n",
    "            orig_df = pd.read_parquet(output_file)\n",
    "            pd.concat([orig_df, df], ignore_index=True).to_parquet(output_file)\n",
    "        else:\n",
    "            df.to_parquet(output_file)\n",
    "            append_mode = True   \n",
    "        return append_mode\n",
    "    \n",
    "    \n",
    "    # 輸出句子對(依章節單位)\n",
    "    for pmcid in pmcids:\n",
    "        ext, abstract = process_article(pmcid, threshold)\n",
    "        for section in 'IMRD':\n",
    "            ext_text = ' '.join(list(ext[ext['section']==section]['text']))\n",
    "            abstract_text = ' '.join(list(abstract[abstract['section']==section]['text']))\n",
    "            pairs.append([ext_text, abstract_text])\n",
    "             \n",
    "        num += 1\n",
    "        if num % batch_size == 0:\n",
    "            print(batch_size)\n",
    "            append_mode = output_batch(pairs, output_file, append_mode)\n",
    "            pairs = []\n",
    "          \n",
    "    if pairs:\n",
    "        append_mode = output_batch(pairs, output_file, append_mode)\n",
    "    \n",
    "    merge_df = pd.read_parquet(output_file)  \n",
    "    return merge_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bd333-b516-444f-b97b-736b27f27be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# set_trigram_blocking = False\n",
    "# generate_ext_abstract_pairs(pmcid_file = '../../dataset/pmcids/train.txt', # or test.txt\n",
    "#                          output_file = '../../dataset/to_abstractive/train_pair.parquet', # or test_pair\n",
    "#                          threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367599b-b094-46fb-9b87-1d3ec5930f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# set_trigram_blocking = True\n",
    "# generate_ext_abstract_pairs(pmcid_file = '../../dataset/pmcids/train.txt', # or test.txt\n",
    "#                          output_file = '../../dataset/to_abstractive/tb_train_pair.parquet', # or test_pair\n",
    "#                          threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2609649-f6ac-4d15-bf6c-90f373ff4708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_rapids",
   "language": "python",
   "name": "python3_rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
